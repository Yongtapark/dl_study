- 내적(dot product)의 다양한 표기법
- 벡터와 행렬에서 내적을 계산하는 방법
- 내적이 인류 문명에서 왜 그렇게 중요한지
---
## Notations for and definition of the dot product

![17.Pasted image 20241001215506](../pic/5.%20Math,%20numpy,%20PyTorch/17.Pasted%20image%2020241001215506.png)

내적 : a와 b의 n개의 요소에 대해 각각의 대응 요소를 곱하고, 그 결과를 모두 합하는 것

---
## Dot product (a.k.a. scalar product) example

![17.Pasted image 20241001215721](../pic/5.%20Math,%20numpy,%20PyTorch/17.Pasted%20image%2020241001215721.png)

	두 벡터 사이의 내적은 항상 하나의 숫자, 단일값이다.
	내적은 두 벡터가 같은 차원을 가질 때만 정의된다.

---
## Dot product in 2D

	합성곱(convolution), 합성곱 신경망(CNN)에 사용

![17.Pasted image 20241001220241](../pic/5.%20Math,%20numpy,%20PyTorch/17.Pasted%20image%2020241001220241.png)

---
## Interpretation of the dot product

<span style="color:rgb(116, 195, 194)">두 객체(벡터, 행렬, 텐서, 신호, 이미지)간의 공통점을 반영하는 하나의 숫자</span>

---
## Applications of the dot product

<span style="font-weight:bold; color:rgb(118, 147, 234)">내적은 많은 연산의 계산적 기반:</span>

<span style="color:rgb(116, 195, 194)">통계 : 상관, 최소제곱법, 엔트로피, 주성분 분성(PCA)</span>
<span style="color:rgb(205, 205, 81)">신호처리 : 푸리에 변환, 필터링</span>
<span style="color:rgb(236, 158, 111)">과학 : 기하학, 물리학, 역학</span>
<span style="color:rgb(230, 122, 122)">선형 대수 : 투영, 변환, 곱셈</span>
딥러닝 : 합성곱, 행렬 곱셉, 그램 행렬(스타일 전이에 사용)

---
## Code : dot product

```python
# create a vector 
nv1 = np.array([1,2,3,4])
nv2 = np.array([0,1,0,-1])

# dot product via function
print(np.dot(nv1,nv2))

# dot product via computation
print(np.sum(nv1*nv2))
```
```
-2
-2
```

```python
# create a vector
tv1 = torch.tensor([1,2,3,4])
tv2 = torch.tensor([0,1,0,-1])

# dot product via function
print(torch.dot(tv1,tv2))

# dot product via computation
print(torch.sum(tv1*tv2))
```
```
tensor(-2)
tensor(-2)
```
