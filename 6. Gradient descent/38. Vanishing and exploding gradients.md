- 기울기 소실과 폭발의 문제접에 대하여
- 이 문제들을 위한 작은 전략들
----
## Vanishing and exploding gradients

### <span style="color:rgb(205, 205, 81)">기울기 소실</span> 

![](38.Pasted%20image%2020241020133432.png)

	기울기가 거의 0에 가까운곳에서 시작해서 지역 최소값을 찾으러 가면 갈수록 기울기가 평평해져 학습률이 낮아짐, 결국 훈련 종료 -> 기울기 소실

<span style="color:rgb(118, 147, 234)">기울기 소실:</span>
<span style="color:rgb(116, 195, 194)">가중치가 변하지 않음 -> 학습이 일어나지 않음.</span>
<span style="color:rgb(116, 195, 194)">깊은 네트워크에서 문제가 됨.</span>

### <span style="color:rgb(205, 205, 81)">기울기 폭주</span> 

![](38.Pasted%20image%2020241020133736.png)

	기울기가 너무 커져서 다음 스텝에서 너무 크게 이동하여 최소값을 지나쳐버리는 경우

<span style="color:rgb(205, 205, 81)">기울기 폭주:</span>
<span style="color:rgb(236, 158, 111)">가중치가 과도하게 변화함 -> 잘못된 해를 초래함</span> 

---
## How to minimize gradient problems

<span style="color:rgb(118, 147, 234)">적은 수의 은닉층을 가진 모델을 사용하라</span>

<span style="color:rgb(116, 195, 194)">ReLU와 같이 포화되지 않는 활성함수를 사용하라</span>

<span style="color:rgb(205, 205, 81)">가중치 정규화를 적용하라</span>

<span style="color:rgb(236, 158, 111)">오토 인코더를 사용하여 네트워크를 사전 훈련하라</span>

<span style="color:rgb(230, 122, 122)">배치 정규화,드롭아웃,가중치 감쇠 같은 정규화 기법을 사용하라</span>

ResNet과 같은 아키텍쳐를 사용하라